{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![AWS SDK for pandas](_static/logo.png \"AWS SDK for pandas\")](https://github.com/aws/aws-sdk-pandas)\n\n# 42 - Amazon S3 Tables\n\n[Amazon S3 Tables](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables.html) provide analytics-optimized tabular storage using Apache Iceberg format. S3 Tables introduce **table buckets**, **namespaces**, and **tables**.\n\nAWS SDK for pandas supports S3 Tables through the `wr.s3` module. Read and write operations require the `pyiceberg` optional dependency:\n\n```\npip install awswrangler[pyiceberg]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install awswrangler[pyiceberg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = getpass.getpass(\"Enter a table bucket name:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Table Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "bucket_arn = wr.s3.create_table_bucket(name=bucket_name)\nprint(f\"Table bucket ARN: {bucket_arn}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "namespace = \"tutorial\"\n\nwr.s3.create_namespace(\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Writing a DataFrame\n\n`to_iceberg` automatically creates the table if it does not exist."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = pd.DataFrame(\n    {\n        \"order_id\": [1, 2, 3],\n        \"amount\": [10.50, 20.00, 15.75],\n        \"region\": [\"us\", \"eu\", \"us\"],\n    }\n)\n\nwr.s3.to_iceberg(\n    df=df,\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n    table_name=\"orders\",\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_new = pd.DataFrame(\n    {\n        \"order_id\": [4, 5],\n        \"amount\": [30.00, 12.25],\n        \"region\": [\"eu\", \"us\"],\n    }\n)\n\nwr.s3.to_iceberg(\n    df=df_new,\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n    table_name=\"orders\",\n    mode=\"append\",\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwriting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_replace = pd.DataFrame(\n    {\n        \"order_id\": [100, 200],\n        \"amount\": [99.99, 49.99],\n        \"region\": [\"ap\", \"ap\"],\n    }\n)\n\nwr.s3.to_iceberg(\n    df=df_replace,\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n    table_name=\"orders\",\n    mode=\"overwrite\",\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read entire table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = wr.s3.from_iceberg(\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n    table_name=\"orders\",\n)\ndf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column selection and row filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = wr.s3.from_iceberg(\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n    table_name=\"orders\",\n    columns=[\"order_id\", \"amount\"],\n    row_filter=\"amount > 50.0\",\n)\ndf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limiting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = wr.s3.from_iceberg(\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n    table_name=\"orders\",\n    limit=1,\n)\ndf"
  },
  {
   "cell_type": "markdown",
   "source": "## Using the AWS Glue Iceberg REST endpoint\n\nBy default, read and write operations use the S3 Tables REST endpoint. To use the [AWS Glue Iceberg REST endpoint](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-integrating-glue-endpoint.html) instead, set `wr.config.s3tables_catalog_endpoint_url`. This enables integration with services that work through the Glue Data Catalog (e.g. Amazon Athena, Amazon Redshift).\n\n### Prerequisites\n\nBefore using the Glue endpoint, your table bucket must be [integrated with the AWS Glue Data Catalog](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-integrating-aws.html). This requires:\n\n1. **An IAM role for Lake Formation** with `s3tables:*` permissions and a trust policy allowing `lakeformation.amazonaws.com` to assume it.\n2. **A Lake Formation resource registration** for `arn:aws:s3tables:<region>:<account>:bucket/*` with `WithFederation=True` and `HybridAccessEnabled=True`.\n3. **A Glue federated catalog** named `s3tablescatalog` linked to S3 Tables via the `aws:s3tables` connection.\n4. **Lake Formation permissions** granting the caller access to the catalog, databases, and tables.\n\nFor step-by-step instructions, see [Integrating S3 Tables with AWS analytics services](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-integrating-aws.html).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Point read/write at the Glue Iceberg REST endpoint\nwr.config.s3tables_catalog_endpoint_url = \"https://glue.<region>.amazonaws.com/iceberg\"\n\ndf = wr.s3.from_iceberg(\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n    table_name=\"orders\",\n)\n\n# Reset to default (S3 Tables endpoint)\nwr.config.s3tables_catalog_endpoint_url = None",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "wr.s3.delete_table(\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n    table_name=\"orders\",\n)\nwr.s3.delete_namespace(\n    table_bucket_arn=bucket_arn,\n    namespace=namespace,\n)\nwr.s3.delete_table_bucket(\n    table_bucket_arn=bucket_arn,\n)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}